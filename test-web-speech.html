<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Web Speech API Test</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
        background-color: #f5f5f5;
      }
      .container {
        background-color: white;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      }
      h1 {
        color: #333;
        text-align: center;
      }
      .controls {
        display: flex;
        justify-content: center;
        margin: 20px 0;
      }
      button {
        background-color: #4a90e2;
        color: white;
        border: none;
        padding: 10px 20px;
        border-radius: 5px;
        cursor: pointer;
        font-size: 16px;
        margin: 0 10px;
      }
      button:hover {
        background-color: #357ab8;
      }
      button.stop {
        background-color: #e25c4a;
      }
      button.stop:hover {
        background-color: #b84735;
      }
      .status {
        text-align: center;
        margin: 10px 0;
        font-weight: bold;
        color: #666;
      }
      .transcript {
        margin-top: 20px;
        padding: 15px;
        background-color: #f9f9f9;
        border-radius: 5px;
        min-height: 100px;
        border: 1px solid #ddd;
      }
      .recording-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        background-color: #e25c4a;
        border-radius: 50%;
        margin-right: 10px;
        animation: pulse 1.5s infinite;
      }
      @keyframes pulse {
        0% {
          opacity: 1;
        }
        50% {
          opacity: 0.3;
        }
        100% {
          opacity: 1;
        }
      }
      .log {
        margin-top: 20px;
        padding: 15px;
        background-color: #f0f0f0;
        border-radius: 5px;
        height: 150px;
        overflow-y: auto;
        font-family: monospace;
        font-size: 12px;
        border: 1px solid #ddd;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Web Speech API Test</h1>

      <div class="controls">
        <button id="startBtn">Start Recording</button>
        <button id="stopBtn" class="stop" disabled>Stop Recording</button>
      </div>

      <div class="status" id="status">Ready</div>

      <div class="transcript" id="transcript">
        <p>Transcript will appear here...</p>
      </div>

      <div class="log" id="log">
        <p>Logs will appear here...</p>
      </div>
    </div>

    <script>
      // DOM elements
      const startBtn = document.getElementById("startBtn");
      const stopBtn = document.getElementById("stopBtn");
      const statusEl = document.getElementById("status");
      const transcriptEl = document.getElementById("transcript");
      const logEl = document.getElementById("log");

      // Variables
      let recognition = null;
      let isRecording = false;
      let transcript = "";

      // Log function
      function log(message) {
        const logEntry = document.createElement("p");
        logEntry.textContent = `${new Date().toLocaleTimeString()}: ${message}`;
        logEl.appendChild(logEntry);
        logEl.scrollTop = logEl.scrollHeight;
        console.log(message);
      }

      // Check if Web Speech API is supported
      if (
        !("webkitSpeechRecognition" in window) &&
        !("SpeechRecognition" in window)
      ) {
        log("Web Speech API is not supported in this browser");
        statusEl.textContent = "Error: Web Speech API not supported";
        startBtn.disabled = true;
      } else {
        log("Web Speech API is supported");
      }

      // Initialize speech recognition
      function initSpeechRecognition() {
        const SpeechRecognition =
          window.SpeechRecognition || window.webkitSpeechRecognition;

        if (!SpeechRecognition) {
          log(
            "SpeechRecognition not found even though it was detected earlier"
          );
          return false;
        }

        recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = "en-US";

        // Set up event handlers
        recognition.onstart = () => {
          log("Speech recognition started");
          isRecording = true;
          updateStatus("Listening...", true);
          startBtn.disabled = true;
          stopBtn.disabled = false;
        };

        recognition.onresult = (event) => {
          let finalTranscript = "";
          let interimTranscript = "";

          for (let i = event.resultIndex; i < event.results.length; i++) {
            const result = event.results[i];
            const text = result[0].transcript;

            if (result.isFinal) {
              finalTranscript += text;
              log(`Final transcript: ${text}`);
            } else {
              interimTranscript += text;
              log(`Interim transcript: ${text}`);
            }
          }

          if (finalTranscript) {
            transcript += finalTranscript + " ";
          }

          updateTranscript(transcript, interimTranscript);
        };

        recognition.onerror = (event) => {
          log(
            `Speech recognition error: ${event.error} - ${
              event.message || "No message"
            }`
          );
          updateStatus(`Error: ${event.error}`);

          if (event.error === "not-allowed") {
            log("Microphone permission denied");
            updateStatus(
              "Error: Microphone access denied. Please allow microphone access in your browser settings."
            );
            stopRecording();
          }
        };

        recognition.onend = () => {
          log("Speech recognition ended");

          if (isRecording) {
            // Try to restart if we're still supposed to be recording
            try {
              log("Attempting to restart recognition...");
              recognition.start();
              log("Recognition restarted successfully");
            } catch (err) {
              log(`Failed to restart recognition: ${err.message}`);
              stopRecording();
            }
          }
        };

        return true;
      }

      // Start recording
      async function startRecording() {
        if (isRecording) return;

        try {
          // Request microphone permission
          log("Requesting microphone permission...");
          await navigator.mediaDevices.getUserMedia({ audio: true });
          log("Microphone permission granted");

          // Initialize speech recognition if not already done
          if (!recognition && !initSpeechRecognition()) {
            return;
          }

          // Start recognition
          recognition.start();
        } catch (err) {
          log(`Error starting recording: ${err.message}`);
          updateStatus(
            "Error: Microphone access denied. Please allow microphone access in your browser settings."
          );
        }
      }

      // Stop recording
      function stopRecording() {
        if (!isRecording) return;

        if (recognition) {
          try {
            recognition.stop();
            log("Recognition stopped");
          } catch (err) {
            log(`Error stopping recognition: ${err.message}`);
          }
        }

        isRecording = false;
        updateStatus("Stopped");
        startBtn.disabled = false;
        stopBtn.disabled = true;
      }

      // Update status display
      function updateStatus(message, isRecording = false) {
        if (isRecording) {
          statusEl.innerHTML = `<span class="recording-indicator"></span>${message}`;
        } else {
          statusEl.textContent = message;
        }
      }

      // Update transcript display
      function updateTranscript(final, interim = "") {
        if (final || interim) {
          transcriptEl.innerHTML = `<p>${final}<span style="color: #999;">${interim}</span></p>`;
        } else {
          transcriptEl.innerHTML = "<p>Transcript will appear here...</p>";
        }
      }

      // Event listeners
      startBtn.addEventListener("click", startRecording);
      stopBtn.addEventListener("click", stopRecording);

      // Initialize
      log("Page loaded");
      updateStatus("Ready");
    </script>
  </body>
</html>
